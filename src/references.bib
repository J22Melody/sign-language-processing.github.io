@inproceedings{detection:borg2019sign,
    title = {Sign Language Detection "in the Wild" with Recurrent Neural Networks},
    author = {Borg, Mark and Camilleri, Kenneth P},
    booktitle = {ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    pages = {1637--1641},
    year = {2019},
    organization = {IEEE}
}

@article{detection:moryossef2020real,
    title = {Real-Time Sign-Language Detection using Human Pose Estimation},
    author = {Moryossef, Amit and Tsochantaridis, Ioannis and Aharoni, Roee Yosef and Ebling, Sarah and Narayanan, Srini},
    year = {2020},
    booktitle = {SLRTP 2020: The Sign Language Recognition, Translation & Production Workshop},
}

@article{simonyan2015very,
    title = {Very deep convolutional networks for large-scale image recognition},
    author = {Simonyan, Karen and Zisserman, Andrew},
    journal={CoRR},
    year = {2015}
}

@inproceedings{cho2014learning,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1179",
    doi = "10.3115/v1/D14-1179",
    pages = "1724--1734",
}

@inproceedings{dataset:vintar2012compiling,
    title={Compiling the Slovene Sign Language Corpus},
    author={Vintar, {\v{S}}pela and Jerko, Bo{\v{s}}tjan and Kulovec, Marjetka},
    booktitle={5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon. Language Resources and Evaluation Conference (LREC)},
    volume={5},
    pages={159--162},
    year={2012}
}

@misc{dataset:databases2007volumes,
    title={Volumes 2--7},
    author={Databases, NCSLGR},
    year={2007},
    publisher={American Sign Language Linguistic Research Project (Distributed on CD-ROM~…}
}

@inproceedings{dataset:imashev2020dataset,
    title={A Dataset for Linguistic Understanding, Visual Evaluation, and Recognition of Sign Languages: The K-RSL},
    author={Imashev, Alfarabi and Mukushev, Medet and Kimmelman, Vadim and Sandygulova, Anara},
    booktitle={Proceedings of the 24th Conference on Computational Natural Language Learning},
    pages={631--640},
    year={2020}
}

@article{dataset:sincan2020autsl,
    title={AUTSL: A Large Scale Multi-Modal Turkish Sign Language Dataset and Baseline Methods},
    author={Sincan, Ozge Mercanoglu and Keles, Hacer Yalim},
    journal={IEEE Access},
    volume={8},
    pages={181340--181355},
    year={2020},
    publisher={IEEE}
}

@article{dataset:duarte2020how2sign,
    title={How2Sign: A Large-scale Multimodal Dataset for Continuous American Sign Language},
    author={Duarte, Amanda and Palaskar, Shruti and Ghadiyaram, Deepti and DeHaan, Kenneth and Metze, Florian and Torres, Jordi and Giro-i-Nieto, Xavier},
    journal={arXiv preprint arXiv:2008.08143},
    year={2020}
}

@inproceedings{dataset:oqvist-etal-2020-sts,
    title = "{STS}-korpus: A Sign Language Web Corpus Tool for Teaching and Public Use",
    author = {{\"O}qvist, Zrajm  and
      Riemer Kankkonen, Nikolaus  and
      Mesch, Johanna},
    booktitle = "Proceedings of the LREC2020 9th Workshop on the Representation and Processing of Sign Languages: Sign Language Resources in the Service of the Language Community, Technological Challenges and Application Perspectives",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/2020.signlang-1.29",
    pages = "177--180",
    abstract = "In this paper we describe STS-korpus, a web corpus tool for Swedish Sign Language (STS) which we have built during the past year, and which is now publicly available on the internet. STS-korpus uses the data of Swedish Sign Language Corpus (SSLC) and is primarily intended for teachers and students of sign language. As such it is created to be simple and user-friendly with no download or setup required. The user interface allows for searching {--} with search results displayed as a simple concordance {--} and viewing of videos with annotations. Each annotation also provides additional data and links to the corresponding entry in the online Swedish Sign Language Dictionary. We describe the corpus, its appearance and search syntax, as well as more advanced features like access control and dynamic content. Finally we say a word or two about the role we hope it will play in the classroom, and something about the development process and the software used. STS-korpus is available here: https://teckensprakskorpus.su.se",
    language = "English",
    ISBN = "979-10-95546-54-2",
}

@inproceedings{dataset:dreuw2006modeling,
    title={Modeling image variability in appearance-based gesture recognition},
    author={Dreuw, Philippe and Deselaers, Thomas and Keysers, Daniel and Ney, Hermann},
    booktitle={ECCV workshop on statistical methods in multi-image and video processing},
    pages={7--18},
    year={2006}
}

@inproceedings{dataset:othman2012english,
    title={English-asl gloss parallel corpus 2012: Aslg-pc12},
    author={Othman, Achraf and Jemni, Mohamed},
    booktitle={5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon LREC},
    year={2012}
}

@inproceedings{dataset:li2020word,
    title={Word-level Deep Sign Language Recognition from Video: A New Large-scale Dataset and Methods Comparison},
    author={Li, Dongxu and Rodriguez, Cristian and Yu, Xin and Li, Hongdong},
    booktitle={The IEEE Winter Conference on Applications of Computer Vision},
    pages={1459--1469},
    year={2020}
}

@inproceedings{dataset:mesch2012meaning,
    title={From meaning to signs and back: Lexicography and the Swedish Sign Language Corpus},
    author={Mesch, Johanna and Wallin, Lars},
    booktitle={Proceedings of the 5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon [Language Resources and Evaluation Conference (LREC)]},
    pages={123--126},
    year={2012}
}

@inproceedings{dataset:acheta2014ACD,
    title={A Corpus-based Dictionary of Polish Sign Language (PJM)},
    author={Joanna Łacheta and Paweł Rutkowski},
    year={2014}
}

@inproceedings{dataset:camgoz-etal-2016-bosphorussign,
    title = "{B}osphorus{S}ign: A {T}urkish {S}ign {L}anguage Recognition Corpus in Health and Finance Domains",
    author = {Camg{\"o}z, Necati Cihan and K{\i}nd{\i}ro{\u {g}} lu, Ahmet Alp and Karab{\"u}kl{\"u}, Serpil and Kelepir, Meltem and {\"O}zsoy, Ay{\c {s}} e Sumru and Akarun, Lale},
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/L16-1220",
    pages = "1383--1388",
    abstract = "There are as many sign languages as there are deaf communities in the world. Linguists have been collecting corpora of different sign languages and annotating them extensively in order to study and understand their properties. On the other hand, the field of computer vision has approached the sign language recognition problem as a grand challenge and research efforts have intensified in the last 20 years. However, corpora collected for studying linguistic properties are often not suitable for sign language recognition as the statistical methods used in the field require large amounts of data. Recently, with the availability of inexpensive depth cameras, groups from the computer vision community have started collecting corpora with large number of repetitions for sign language recognition research. In this paper, we present the BosphorusSign Turkish Sign Language corpus, which consists of 855 sign and phrase samples from the health, finance and everyday life domains. The corpus is collected using the state-of-the-art Microsoft Kinect v2 depth sensor, and will be the first in this sign language research field. Furthermore, there will be annotations rendered by linguists so that the corpus will appeal both to the linguistic and sign language recognition research communities.",
}

@inproceedings{dataset:hanke-etal-2020-extending,
    title = "Extending the {P}ublic {DGS} {C}orpus in Size and Depth",
    author = "Hanke, Thomas  and
      Schulder, Marc  and
      Konrad, Reiner  and
      Jahn, Elena",
    booktitle = "Proceedings of the LREC2020 9th Workshop on the Representation and Processing of Sign Languages: Sign Language Resources in the Service of the Language Community, Technological Challenges and Application Perspectives",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/2020.signlang-1.12",
    pages = "75--82",
    abstract = "In 2018 the DGS-Korpus project published the first full release of the Public DGS Corpus. This event marked a change of focus for the project. While before most attention had been on increasing the size of the corpus, now an increase in its depth became the priority. New data formats were added, corpus annotation conventions were released and OpenPose pose information was published for all transcripts. The community and research portal websites of the corpus also received upgrades, including persistent identifiers, archival copies of previous releases and improvements to their usability on mobile devices.The research portal was enhanced even further, improving its transcript web viewer, adding a KWIC concordance view, introducing cross-references to other linguistic resources of DGS and making its entire interface available in German in addition to English. This article provides an overview of these changes, chronicling the evolution of the Public DGS Corpus from its first release in 2018, through its second release in 2019 until its third release in 2020.",
    language = "English",
    ISBN = "979-10-95546-54-2",
}

@inproceedings{dataset:hassan-etal-2020-isolated,
    title = "An Isolated-Signing {RGBD} Dataset of 100 {A}merican {S}ign {L}anguage Signs Produced by Fluent {ASL} Signers",
    author = "Hassan, Saad  and
      Berke, Larwan  and
      Vahdani, Elahe  and
      Jing, Longlong  and
      Tian, Yingli  and
      Huenerfauth, Matt",
    booktitle = "Proceedings of the LREC2020 9th Workshop on the Representation and Processing of Sign Languages: Sign Language Resources in the Service of the Language Community, Technological Challenges and Application Perspectives",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/2020.signlang-1.14",
    pages = "89--94",
    abstract = "We have collected a new dataset consisting of color and depth videos of fluent American Sign Language (ASL) signers performing sequences of 100 ASL signs from a Kinect v2 sensor. This directed dataset had originally been collected as part of an ongoing collaborative project, to aid in the development of a sign-recognition system for identifying occurrences of these 100 signs in video. The set of words consist of vocabulary items that would commonly be learned in a first-year ASL course offered at a university, although the specific set of signs selected for inclusion in the dataset had been motivated by project-related factors. Given increasing interest among sign-recognition and other computer-vision researchers in red-green-blue-depth (RBGD) video, we release this dataset for use by the research community. In addition to the RGB video files, we share depth and HD face data as well as additional features of face, hands, and body produced through post-processing of this data.",
    language = "English",
    ISBN = "979-10-95546-54-2",
}

@inproceedings{dataset:hassan-etal-2022-asl-homework,
  author    = {Hassan, Saad and Seita, Matthew and Berke, Larwan and Tian, Yingli and Gale, Elaine and Lee, Sooyeon and Huenerfauth, Matt},
  title     = {{ASL-Homework-RGBD} Dataset: An Annotated Dataset of {45} Fluent and Non-fluent Signers Performing {American} {Sign} {Language} Homeworks},
  pages     = {67--72},
  editor    = {Efthimiou, Eleni and Fotinea, Stavroula-Evita and Hanke, Thomas and Hochgesang, Julie A. and Kristoffersen, Jette and Mesch, Johanna and Schulder, Marc},
  booktitle = {Proceedings of the {LREC2022} 10th Workshop on the Representation and Processing of Sign Languages: Multilingual Sign Language Resources},
  maintitle = {13th International Conference on Language Resources and Evaluation ({LREC} 2022)},
  publisher = {{European Language Resources Association (ELRA)}},
  address   = {Marseille, France},
  day       = {25},
  month     = jun,
  year      = {2022},
  isbn      = {979-10-95546-86-3},
  language  = {english},
  url       = {https://www.sign-lang.uni-hamburg.de/lrec/pub/22008.pdf}
}

@article{dataset:fs18slt,
    author = {B. Shi and A. Martinez Del Rio and J. Keane and J. Michaux and D. Brentari, G. Shakhnarovich and K. Livescu},
    title = {American Sign Language fingerspelling recognition in the wild},
    journal = {SLT},
    year = {2018},
    month = {December}
}

@article{dataset:fs18iccv,
    author = {B. Shi and A. Martinez Del Rio and J. Keane and D. Brentari and G. Shakhnarovich and K. Livescu},
    title = {Fingerspelling recognition in the wild with iterative visual attention},
    journal = {ICCV},
    year = {2019},
    month = {October}
}

@inproceedings{dataset:zafrulla2010novel,
    title = {A novel approach to american sign language ({ASL}) phrase verification using reversed signing},
    author = {Zafrulla, Zahoor and Brashear, Helene and Hamilton, Harley and Starner, Thad},
    booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops},
    pages = {48--55},
    year = {2010},
    organization = {IEEE}
}

@article{dataset:chai2014devisign,
    title = {The devisign large vocabulary of chinese sign language database and baseline evaluations},
    author = {Chai, Xiujuan and Wang, Hanjie and Chen, Xilin},
    journal = {Technical report VIPL-TR-14-SLR-001. Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS},
    year = {2014}
}

@inproceedings{dataset:matthes2012dicta,
    title = {Dicta-Sign--building a multilingual sign language corpus},
    author = {Matthes, Silke and Hanke, Thomas and Regen, Anja and Storz, Jakob and Worseck, Satu and Efthimiou, Eleni and Dimou, Athanasia-Lida and Braffort, Annelies and Glauert, John and Safar, Eva},
    booktitle = {Proceedings of the 5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon (LREC 2012)},
    year = {2012}
}

@inproceedings{dataset:forster2014extensions,
    title = {Extensions of the Sign Language Recognition and Translation Corpus RWTH-PHOENIX-Weather.},
    author = {Forster, Jens and Schmidt, Christoph and Koller, Oscar and Bellgardt, Martin and Ney, Hermann},
    booktitle = {LREC},
    pages = {1911--1916},
    year = {2014}
}

@InProceedings{dataset:joze2018ms,
    author = {Vaezi Joze, Hamid and Koller, Oscar},
    title = {MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language},
    booktitle = {The British Machine Vision Conference (BMVC)},
    year = {2019},
    month = {September},
    abstract = {Computer Vision has been improved significantly in the past few decades. It has enabled machine to do many human tasks. However, the real challenge is in enabling machine to carry out tasks that an average human does not have the skills for. One such challenge that we have tackled in this paper is providing accessibility for deaf individual by providing means of communication with others with the aid of computer vision. Unlike other frequent works focusing on multiple camera, depth camera, electrical glove or visual gloves, we focused on the sole use of RGB which allows everybody to communicate with a deaf individual through their personal devices. This is not a new approach but the lack of realistic large-scale data set prevented recent computer vision trends on video classification in this filed.
    In this paper, we propose the first large scale ASL data set that covers over 200 signers, signer independent sets, challenging and unconstrained recording conditions and a large class count of 1000 signs. We evaluate baselines from action recognition techniques on the data set. We propose I3D, known from video classifications, as a powerful and suitable architecture for sign language recognition. We also propose new pre-trained model more appropriate for sign language recognition. Finally, We estimate the effect of number of classes and number of training samples on the recognition accuracy.},
    url = {https://www.microsoft.com/en-us/research/publication/ms-asl-a-large-scale-data-set-and-benchmark-for-understanding-american-sign-language/},
}

@article{dataset:gutierrez2016lse,
    title = {LSE-sign: A lexical database for spanish sign language},
    author = {Gutierrez-Sigut, Eva and Costello, Brendan and Baus, Cristina and Carreiras, Manuel},
    journal = {Behavior Research Methods},
    volume = {48},
    number = {1},
    pages = {123--137},
    year = {2016},
    publisher = {Springer}
}

@inproceedings{dataset:athitsos2008american,
    title = {The american sign language lexicon video dataset},
    author = {Athitsos, Vassilis and Neidle, Carol and Sclaroff, Stan and Nash, Joan and Stefan, Alexandra and Yuan, Quan and Thangali, Ashwin},
    booktitle = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
    pages = {1--8},
    year = {2008},
    organization = {IEEE}
}

@inproceedings{dataset:dreuw2008benchmark,
    title = {Benchmark Databases for Video-Based Automatic Sign Language Recognition.},
    author = {Dreuw, Philippe and Neidle, Carol and Athitsos, Vassilis and Sclaroff, Stan and Ney, Hermann},
    booktitle = {LREC},
    year = {2008}
}

@article{dataset:von2007towards,
    title = {Towards a video corpus for signer-independent continuous sign language recognition},
    author = {Von Agris, Ulrich and Kraiss, Karl-Friedrich},
    journal = {Gesture in Human-Computer Interaction and Simulation, Lisbon, Portugal, May},
    volume = {11},
    year = {2007}
}

@inproceedings{dataset:viitaniemi-etal-2014-pot,
    title = "{S}-pot - a benchmark in spotting signs within continuous signing",
    author = "Viitaniemi, Ville  and
      Jantunen, Tommi  and
      Savolainen, Leena  and
      Karppa, Matti  and
      Laaksonen, Jorma",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/440_Paper.pdf",
    pages = "1892--1897",
    abstract = "In this paper we present S-pot, a benchmark setting for evaluating the performance of automatic spotting of signs in continuous sign language videos. The benchmark includes 5539 video files of Finnish Sign Language, ground truth sign spotting results, a tool for assessing the spottings against the ground truth, and a repository for storing information on the results. In addition we will make our sign detection system and results made with it publicly available as a baseline for comparison and further developments.",
}

@article{dataset:ko2019neural,
    title={Neural sign language translation based on human keypoint estimation},
    author={Ko, Sang-Ki and Kim, Chang Jo and Jung, Hyedong and Cho, Choongsang},
    journal={Applied Sciences},
    volume={9},
    number={13},
    pages={2683},
    year={2019},
    publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{dataset:ebling2018smile,
    title = "{SMILE} {S}wiss {G}erman Sign Language Dataset",
    author = {Ebling, Sarah and
 Camg {\"o} z, Necati Cihan and
 Boyes Braem, Penny and
 Tissi, Katja and
 Sidler-Miserez, Sandra and
 Stoll, Stephanie and
 Hadfield, Simon and
 Haug, Tobias and
 Bowden, Richard and
 Tornay, Sandrine and
 Razavi, Marzieh and
 Magimai-Doss, Mathew},
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/L18-1666",
}

@inproceedings{dataset:bungeroth2008atis,
    title = "The {ATIS} Sign Language Corpus",
    author = "Bungeroth, Jan  and
      Stein, Daniel  and
      Dreuw, Philippe  and
      Ney, Hermann  and
      Morrissey, Sara  and
      Way, Andy  and
      van Zijl, Lynette",
    booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
    month = may,
    year = "2008",
    address = "Marrakech, Morocco",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/748_paper.pdf",
    abstract = "Systems that automatically process sign language rely on appropriate data. We therefore present the ATIS sign language corpus that is based on the domain of air travel information. It is available for five languages, English, German, Irish sign language, German sign language and South African sign language. The corpus can be used for different tasks like automatic statistical translation and automatic sign language recognition and it allows the specific modeling of spatial references in signing space.",
}

@inproceedings{dataset:Crasborn2008TheCN,
    title = {The Corpus NGT: An online corpus for professionals and laymen},
    author = {O. Crasborn and I. Zwitserlood},
    year = {2008}
}

@inproceedings{dataset:huang2018video,
    title={Video-based sign language recognition without temporal segmentation},
    author={Huang, Jie and Zhou, Wengang and Zhang, Qilin and Li, Houqiang and Li, Weiping},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={32},
    number={1},
    year={2018}
}

@article{dataset:schembri2013building,
    title = {Building the British sign language corpus},
    author = {Schembri, Adam and Fenlon, Jordan and Rentelis, Ramas and Reynolds, Sally and Cormier, Kearsy},
    journal = {Language Documentation \& Conservation},
    volume = {7},
    pages = {136--154},
    year = {2013},
    publisher = {University of Hawaii Press}
}

@article{dataset:johnston2010archive,
    title = {From archive to corpus: Transcription and annotation in the creation of signed language corpora},
    author = {Johnston, Trevor},
    journal = {International journal of corpus linguistics},
    volume = {15},
    number = {1},
    pages = {106--131},
    year = {2010},
    publisher = {John Benjamins}
}

@inproceedings{dataset:martinez2002purdue,
    title={Purdue RVL-SLLL ASL database for automatic recognition of American Sign Language},
    author={Mart{\'i}nez, Aleix M and Wilbur, Ronnie B and Shay, Robin and Kak, Avinash C},
    booktitle={Proceedings. Fourth IEEE International Conference on Multimodal Interfaces},
    pages={167--172},
    year={2002},
    organization={IEEE}
}

@inproceedings{dataset:camgoz2021content4all,
  title={Content4all open research sign language translation datasets},
  author={Camg{\"o}z, Necati Cihan and Saunders, Ben and Rochette, Guillaume and Giovanelli, Marco and Inches, Giacomo and Nachtrab-Ribback, Robin and Bowden, Richard},
  booktitle={2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)},
  pages={1--5},
  year={2021},
  organization={IEEE}
}

@inproceedings{dataset:mukushev2022towards,
  author    = {Mukushev, Medet and Kydyrbekova, Aigerim and Kimmelman, Vadim and Sandygulova, Anara},
  title     = {Towards Large Vocabulary {Kazakh-Russian} {Sign} {Language} Dataset: {KRSL-OnlineSchool}},
  pages     = {154--158},
  editor    = {Efthimiou, Eleni and Fotinea, Stavroula-Evita and Hanke, Thomas and Hochgesang, Julie A. and Kristoffersen, Jette and Mesch, Johanna and Schulder, Marc},
  booktitle = {Proceedings of the {LREC2022} 10th Workshop on the Representation and Processing of Sign Languages: Multilingual Sign Language Resources},
  maintitle = {13th International Conference on Language Resources and Evaluation ({LREC} 2022)},
  publisher = {{European Language Resources Association (ELRA)}},
  address   = {Marseille, France},
  day       = {25},
  month     = jun,
  year      = {2022},
  isbn      = {979-10-95546-86-3},
  language  = {english},
  url       = {https://www.sign-lang.uni-hamburg.de/lrec/pub/22031.pdf}
}

@inproceedings{identification:gebre2013automatic,
    title = {Automatic sign language identification},
    author = {Gebre, Binyam Gebrekidan and Wittenburg, Peter and Heskes, Tom},
    booktitle = {2013 IEEE International Conference on Image Processing},
    pages = {2626--2630},
    year = {2013},
    organization = {IEEE}
}


@inproceedings{identification:monteiro2016detecting,
    title = {Detecting and identifying sign languages through visual features},
    author = {Monteiro, Caio DD and Mathew, Christy Maria and Gutierrez-Osuna, Ricardo and Shipman, Frank},
    booktitle = {2016 IEEE International Symposium on Multimedia (ISM)},
    pages = {287--290},
    year = {2016},
    organization = {IEEE}
}

@inproceedings{segmentation:santemiz2009automatic,
  title={Automatic sign segmentation from continuous signing via multiple sequence alignment},
  author={Santemiz, Pinar and Aran, Oya and Saraclar, Murat and Akarun, Lale},
  booktitle={2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops},
  pages={2001--2008},
  year={2009},
  organization={IEEE}
}

@inproceedings{segmentation:bull2020automatic,
  title={Automatic segmentation of sign language into subtitle-units},
  author={Bull, Hannah and Gouiff{\`e}s, Mich{\`e}le and Braffort, Annelies},
  booktitle={European Conference on Computer Vision},
  pages={186--198},
  year={2020},
  organization={Springer}
}

@inproceedings{segmentation:farag2019learning,
  title={Learning motion disfluencies for automatic sign language segmentation},
  author={Farag, Iva and Brock, Heike},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7360--7364},
  year={2019},
  organization={IEEE}
}

@inproceedings{segmentation:renz2021signa,
  title={Sign language segmentation with temporal convolutional networks},
  author={Renz, Katrin and Stache, Nicolaj C and Albanie, Samuel and Varol, G{\"u}l},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2135--2139},
  year={2021},
  organization={IEEE}
}

@inproceedings{segmentation:renz2021signb,
  title={Sign segmentation with changepoint-modulated pseudo-labelling},
  author={Renz, Katrin and Stache, Nicolaj C and Fox, Neil and Varol, Gul and Albanie, Samuel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3403--3412},
  year={2021}
}

@inproceedings{segmentation:bull2021aligning,
  title={Aligning subtitles in sign language videos},
  author={Bull, Hannah and Afouras, Triantafyllos and Varol, G{\"u}l and Albanie, Samuel and Momeni, Liliane and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11552--11561},
  year={2021}
}

@book{writing:bergman1977tecknad,
    title={Tecknad svenska:[Signed Swedish]},
    author={Bergman, Brita},
    year={1977},
    publisher={LiberL{\"a}romedel/Utbildningsf{\"o}rl.:}
}

@inproceedings{writing:prillwitz1990hamburg,
    title = {Hamburg Notation System for Sign Language: Development of a sign writing with computer application},
    author = {Prillwitz, Siegmund and Zienert, Heiko},
    booktitle = {Current trends in European Sign Language Research. Proceedings of the 3rd European Congress on Sign Language Research},
    pages = {355--379},
    year = {1990}
}

@article{writing:stokoe2005sign,
    title = {Sign language structure: An outline of the visual communication systems of the American deaf},
    author = {Stokoe Jr, William C},
    journal = {Journal of deaf studies and deaf education},
    volume = {10},
    number = {1},
    pages = {3--37},
    year = {2005},
    publisher = {Oxford University Press}
}

@book{writing:sutton1990lessons,
    title={Lessons in sign writing},
    author={Sutton, Valerie},
    year={1990},
    publisher={SignWriting}
}

@inproceedings{pose:pishchulin2012articulated,
    title = {Articulated people detection and pose estimation: Reshaping the future},
    author = {Pishchulin, Leonid and Jain, Arjun and Andriluka, Mykhaylo and Thorm {\"a} hlen, Thorsten and Schiele, Bernt},
    booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
    pages = {3178--3185},
    year = {2012},
    organization = {IEEE}
}

@inproceedings{pose:hidalgo2019singlenetwork,
    author = {Gines Hidalgo and Yaadhav Raaj and Haroon Idrees and Donglai Xiang and Hanbyul Joo and Tomas Simon and Yaser Sheikh},
    booktitle = {ICCV},
    title = {Single-Network Whole-Body Pose Estimation},
    year = {2019}
}

@inproceedings{pose:chen2017adversarial,
    title = {Adversarial posenet: A structure-aware convolutional network for human pose estimation},
    author = {Chen, Yu and Shen, Chunhua and Wei, Xiu-Shen and Liu, Lingqiao and Yang, Jian},
    booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
    pages = {1212--1221},
    year = {2017}
}

@inproceedings{pose:alp2018densepose,
    title = {Densepose: Dense human pose estimation in the wild},
    author = {G{\"u}ler, R{\i}za Alp and Neverova, Natalia and Kokkinos, Iasonas},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages = {7297--7306},
    year = {2018}
}

@inproceedings{pose:pavllo20193d,
    title = {3d human pose estimation in video with temporal convolutions and semi-supervised training},
    author = {Pavllo, Dario and Feichtenhofer, Christoph and Grangier, David and Auli, Michael},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages = {7753--7762},
    year = {2019}
}

@inproceedings{pose:panteleris2018using,
    title = {Using a single rgb frame for real time 3d hand pose estimation in the wild},
    author = {Panteleris, Paschalis and Oikonomidis, Iason and Argyros, Antonis},
    booktitle = {2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
    pages = {436--445},
    year = {2018},
    organization = {IEEE}
}

@article{pose:cao2018openpose,
    author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
    year = {2019}
}

@inproceedings{pose:simon2017hand,
    author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},
    booktitle = {CVPR},
    title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},
    year = {2017}
}

@inproceedings{pose:cao2017realtime,
    author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},
    booktitle = {CVPR},
    title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
    year = {2017}
}

@inproceedings{pose:wei2016cpm,
    author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},
    booktitle = {CVPR},
    title = {Convolutional pose machines},
    year = {2016}
}

@inproceedings{pose:chan2019everybody,
    title = {Everybody dance now},
    author = {Chan, Caroline and Ginosar, Shiry and Zhou, Tinghui and Efros, Alexei A},
    booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
    pages = {5933--5942},
    year = {2019}
}

@inproceedings{isola2017image,
    title = {Image-to-image translation with conditional adversarial networks},
    author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    pages = {1125--1134},
    year = {2017}
}

@article{nguyen2019deep,
    author    = {Thanh Thi Nguyen and
               Cuong M. Nguyen and
               Dung Tien Nguyen and
               Duc Thanh Nguyen and
               Saeid Nahavandi},
    title     = {Deep Learning for Deepfakes Creation and Detection},
    journal   = {CoRR},
    volume    = {abs/1909.11573},
    year      = {2019},
    url       = {http://arxiv.org/abs/1909.11573},
    archivePrefix = {arXiv},
    eprint    = {1909.11573},
    timestamp = {Thu, 27 Aug 2020 17:49:18 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/abs-1909-11573.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pose:girocan2020slrtp,
    title = {Can Everybody Sign Now? Exploring Sign Language Video Generation from 2D Poses},
    author = {Gir{\'o}-i-Nieto, Xavier},
    year = {2020},
}

@inproceedings{pose:wang2018vid2vid,
    author    = {Ting-Chun Wang and Ming-Yu Liu and Jun-Yan Zhu and Guilin Liu
                and Andrew Tao and Jan Kautz and Bryan Catanzaro},
    title     = {Video-to-Video Synthesis},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2018},
}

@inproceedings{stoll2018sign,
    title={Sign language production using neural machine translation and generative adversarial networks},
    author={Stoll, Stephanie and Camg{\"o}z, Necati Cihan and Hadfield, Simon and Bowden, Richard},
    booktitle={Proceedings of the 29th British Machine Vision Conference (BMVC 2018)},
    year={2018},
    organization={British Machine Vision Association}
}

@inproceedings{goodfellow2014generative,
    title={Generative adversarial nets},
    author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle={Advances in neural information processing systems},
    pages={2672--2680},
    year={2014}
}

@article{stoll2020text2sign,
    title={Text2Sign: towards sign language production using neural machine translation and generative adversarial networks},
    author={Stoll, Stephanie and Camg{\"o}z, Necati Cihan and Hadfield, Simon and Bowden, Richard},
    journal={International Journal of Computer Vision},
    pages={1--18},
    year={2020},
    publisher={Springer}
}

@article{min2012motion,
    title={Motion graphs++ a compact generative model for semantic motion analysis and synthesis},
    author={Min, Jianyuan and Chai, Jinxiang},
    journal={ACM Transactions on Graphics (TOG)},
    volume={31},
    number={6},
    pages={1--12},
    year={2012},
    publisher={ACM New York, NY, USA}
}

@article{savitzky1964smoothing,
    title={Smoothing and differentiation of data by simplified least squares procedures.},
    author={Savitzky, Abraham and Golay, Marcel JE},
    journal={Analytical chemistry},
    volume={36},
    number={8},
    pages={1627--1639},
    year={1964},
    publisher={ACS Publications}
}

@inproceedings{cui2017recurrent,
    title={Recurrent convolutional neural networks for continuous sign language recognition by staged optimization},
    author={Cui, Runpeng and Liu, Hu and Zhang, Changshui},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages={7361--7369},
    year={2017}
}

@inproceedings{graves2006connectionist,
    title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
    author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
    booktitle={Proceedings of the 23rd international conference on Machine learning},
    pages={369--376},
    year={2006}
}

@inproceedings{cihan2018neural,
    title={Neural sign language translation},
    author={Cihan Camg{\"o}z, Necati and Hadfield, Simon and Koller, Oscar and Ney, Hermann and Bowden, Richard},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages={7784--7793},
    year={2018}
}

@inproceedings{yin2020better,
    title={Better Sign Language Translation with STMC-Transformer},
    author={Yin, Kayo and Read, Jesse},
    booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
    pages={5975--5989},
    year={2020}
}

@inproceedings{luong2015effective,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1166",
    doi = "10.18653/v1/D15-1166",
    pages = "1412--1421",
}

@article{bahdanau2014neural,
    title={Neural machine translation by jointly learning to align and translate},
    author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
    editor    = {Yoshua Bengio and
               Yann LeCun},
    title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
    booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
    year      = {2015},
    url       = {http://arxiv.org/abs/1409.0473},
}

@inproceedings{krizhevsky2012imagenet,
    title={Imagenet classification with deep convolutional neural networks},
    author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
    booktitle={Advances in neural information processing systems},
    pages={1097--1105},
    year={2012}
}

@inproceedings{deng2009imagenet,
    title={Imagenet: A large-scale hierarchical image database},
    author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
    booktitle={2009 IEEE conference on computer vision and pattern recognition},
    pages={248--255},
    year={2009},
    organization={Ieee}
}

@inproceedings{camgoz2020sign,
    title={Sign Language Transformers: Joint End-to-end Sign Language Recognition and Translation},
    author={Camg{\"o}z, Necati Cihan and Koller, Oscar and Hadfield, Simon and Bowden, Richard},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={10023--10033},
    year={2020}
}

@inproceedings{camgoz2020multi,
    title={Multi-channel transformers for multi-articulatory sign language translation},
    author={Camg{\"o}z, Necati Cihan and Koller, Oscar and Hadfield, Simon and Bowden, Richard},
    booktitle={European Conference on Computer Vision},
    pages={301--319},
    year={2020}
}

@inproceedings{vaswani2017attention,
    title={Attention is all you need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    booktitle={Advances in neural information processing systems},
    pages={5998--6008},
    year={2017}
}

@article{koller2019weakly,
    title={Weakly supervised learning with multi-stream CNN-LSTM-HMMs to discover sequential parallelism in sign language videos},
    author={Koller, Oscar and Camg{\"o}z, Cihan and Ney, Hermann and Bowden, Richard},
    journal={IEEE transactions on pattern analysis and machine intelligence},
    year={2019},
    publisher={IEEE}
}

@misc{adeline2013fingerspell,
    title={Fingerspell.net},
    author={Adeline, Chloe},
    url={http://fingerspell.net/},
    year={2013}
}

@misc{mediapipe2020holistic,
    title={MediaPipe Holistic},
    author={Grishchenko, Ivan and Bazarevsky, Valentin},
    url={https://google.github.io/mediapipe/solutions/holistic.html},
    year={2020}
}

@inproceedings{kipp2001anvil,
    title={Anvil-a generic annotation tool for multimodal dialogue},
    author={Kipp, Michael},
    booktitle={Seventh European Conference on Speech Communication and Technology},
    year={2001}
}

@inproceedings{wheatland2016analysis,
    title={Analysis in support of realistic timing in animated fingerspelling},
    author={Wheatland, Nkenge and Abdullah, Ahsan and Neff, Michael and J{\"o}rg, Sophie and Zordan, Victor},
    booktitle={2016 IEEE Virtual Reality (VR)},
    pages={309--310},
    year={2016},
    organization={IEEE}
}

@book{patrie2011fingerspelled,
    title={Fingerspelled word recognition through rapid serial visual presentation: RSVP},
    author={Patrie, Carol J and Johnson, Robert E},
    year={2011},
    publisher={DawnSignPress}
}

@article{battison1978lexical,
    title={Lexical borrowing in American sign language.},
    author={Battison, Robbin},
    year={1978},
    publisher={ERIC}
}

@book{wilcox1992phonetics,
    title={The phonetics of fingerspelling},
    author={Wilcox, Sherman},
    volume={4},
    year={1992},
    publisher={John Benjamins Publishing}
}

@article{padden2003alphabet,
    title={How the alphabet came to be used in a sign language},
    author={Padden, Carol A and Gunsauls, Darline Clark},
    journal={Sign Language Studies},
    pages={10--33},
    year={2003},
    publisher={JSTOR}
}

@article{brentari2001language,
    title={A language with multiple origins: Native and foreign vocabulary in American Sign Language},
    author={Brentari, Diane and Padden, Carol},
    journal={Foreign vocabulary in sign language: A cross-linguistic investigation of word formation},
    pages={87--119},
    year={2001},
    publisher={Lawrence Erlbaum Mahwah, NJ}
}

@article{padden1998asl,
    title={The ASL lexicon},
    author={Padden, Carol A},
    journal={Sign language \& linguistics},
    volume={1},
    number={1},
    pages={39--60},
    year={1998},
    publisher={John Benjamins}
}

@article{montemurro2018emphatic,
    title={Emphatic fingerspelling as code-mixing in American Sign Language},
    author={Montemurro, Kathryn and Brentari, Diane},
    journal={Proceedings of the Linguistic Society of America},
    volume={3},
    number={1},
    pages={61--1},
    year={2018}
}

@inproceedings{zhao2000machine,
    title={A machine translation system from English to American Sign Language},
    author={Zhao, Liwei and Kipper, Karin and Schuler, William and Vogler, Christian and Badler, Norman and Palmer, Martha},
    booktitle={Conference of the Association for Machine Translation in the Americas},
    pages={54--67},
    year={2000},
    organization={Springer}
}

@inproceedings{shieber1990synchronous,
    title={Synchronous tree-adjoining grammars},
    author={Shieber, Stuart and Schabes, Yves},
    booktitle={Proceedings of the 13th international conference on computational linguistics},
    year={1990},
    organization={Association for Computational Linguistics}
}

@article{shieber1994restricting,
    title={RESTRICTING THE WEAK-GENERATIVE CAPACITY OF SYNCHRONOUS TREE-ADJOINING GRAMMARS},
    author={Shieber, Stuart M},
    journal={Computational Intelligence},
    volume={10},
    number={4},
    pages={371--385},
    year={1994},
    publisher={Wiley Online Library}
}

@article{abeille1991using,
    title={Using lexicalized tags for machine translation},
    author={Abeill{\'e}, Anne and Schabes, Yves and Joshi, Aravind K},
    year={1991}
}

@misc{lebert2008project,
    title={Project Gutenberg (1971-2008)},
    author={Lebert, Marie},
    year={2008},
    publisher={Project Gutenberg}
}

@inproceedings{wittenburg2006elan,
    title={ELAN: a professional framework for multimodality research},
    author={Wittenburg, Peter and Brugman, Hennie and Russel, Albert and Klassmann, Alex and Sloetjes, Han},
    booktitle={5th International Conference on Language Resources and Evaluation (LREC 2006)},
    pages={1556--1559},
    year={2006}
}

@inproceedings{hanke2002ilex,
    title={iLex-A tool for Sign Language Lexicography and Corpus Analysis.},
    author={Hanke, Thomas},
    booktitle={LREC},
    year={2002}
}

@book{sandler2006sign,
    title={Sign language and linguistic universals},
    author={Sandler, Wendy and Lillo-Martin, Diane},
    year={2006},
    publisher={Cambridge University Press}
}

@inproceedings{bragg2019sign,
    title={Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective},
    author={Bragg, Danielle and Koller, Oscar and Bellard, Mary and Berke, Larwan and Boudreault, Patrick and Braffort, Annelies and Caselli, Naomi and Huenerfauth, Matt and Kacorri, Hernisa and Verhoef, Tessa and others},
    booktitle={The 21st International ACM SIGACCESS Conference on Computers and Accessibility},
    pages={16--31},
    year={2019}
}

@article{neidle2001signstream,
    title={SignStream: A tool for linguistic and computer vision research on visual-gestural language data},
    author={Neidle, Carol and Sclaroff, Stan and Athitsos, Vassilis},
    journal={Behavior Research Methods, Instruments, \& Computers},
    volume={33},
    number={3},
    pages={311--320},
    year={2001},
    publisher={Springer}
}


@misc{pympi-1.69,
    author={Lubbers, Mart and Torreira, Francisco},
    title={pympi-ling: a {Python} module for processing {ELAN}s {EAF} and {Praat}s {TextGrid} annotation files.},
    howpublished={\url{https://pypi.python.org/pypi/pympi-ling}},
    year={2013},
    note={Version 1.69}
}

@inproceedings{vogler2005analysis,
    title={Analysis of facial expressions in american sign language},
    author={Vogler, Christian and Goldenstein, Siome},
    booktitle={Proc, of the 3rd Int. Conf. on Universal Access in Human-Computer Interaction, Springer},
    year={2005}
}

@inproceedings{pose:zelinka2020neural,
    title={Neural Sign Language Synthesis: Words Are Our Glosses},
    author={Zelinka, Jan and Kanis, Jakub},
    booktitle={The IEEE Winter Conference on Applications of Computer Vision},
    pages={3395--3403},
    year={2020}
}

@misc{TFDS,
    title = {{TensorFlow Datasets}, A collection of ready-to-use datasets},
    howpublished = {\url{https://www.tensorflow.org/datasets}},
}

@inproceedings{saunders2020progressive,
    title={Progressive transformers for end-to-end sign language production},
    author={Saunders, Ben and Camg{\"o}z, Necati Cihan and Bowden, Richard},
    booktitle={European Conference on Computer Vision},
    pages={687--705},
    year={2020}
}

@inproceedings{saunders2020adversarial,
    title={Adversarial Training for Multi-Channel Sign Language Production},
    author={Saunders, Ben and Camg{\"o}z, Necati Cihan and Bowden, Richard},
    booktitle={The 31st British Machine Vision Virtual Conference},
    year={2020},
    organization={British Machine Vision Association}
}

@article{saunders2020everybody,
    title={Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign Language Video},
    author={Saunders, Ben and Camg{\"o}z, Necati Cihan and Bowden, Richard},
    journal={arXiv preprint arXiv:2011.09846},
    year={2020}
}

@article{bishop1994mixture,
    title={Mixture density networks},
    author={Bishop, Christopher M},
    year={1994},
    publisher={Aston University}
}

@article{xiao2020skeleton,
    title={Skeleton-based Chinese sign language recognition and generation for bidirectional communication between deaf and hearing people},
    author={Xiao, Qinkun and Qin, Minying and Yin, Yuting},
    journal={Neural Networks},
    volume={125},
    pages={41--55},
    year={2020},
    publisher={Elsevier}
}

@article{adaloglou2020comprehensive,
    title={A comprehensive study on sign language recognition methods},
    author={Adaloglou, Nikolas and Chatzis, Theocharis and Papastratis, Ilias and Stergioulas, Andreas and Papadopoulos, Georgios Th and Zacharopoulou, Vassia and Xydopoulos, George J and Atzakas, Klimnis and Papazachariou, Dimitris and Daras, Petros},
    journal={arXiv preprint arXiv:2007.12530},
    year={2020}
}

@article{jiang2021sign,
  title={Sign language recognition via skeleton-aware multi-model ensemble},
  author={Jiang, Songyao and Sun, Bin and Wang, Lichen and Bai, Yue and Li, Kunpeng and Fu, Yun},
  journal={arXiv preprint arXiv:2110.06161},
  year={2021}
}

@inproceedings{dafnis2022bidirectional,
  title={Bidirectional Skeleton-Based Isolated Sign Recognition using Graph Convolution Networks},
  author={Dafnis, Konstantinos M and Chroni, Evgenia and Neidle, Carol and Metaxas, Dimitris N},
  booktitle={Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022), Marseille, 20-25 June 2022.},
  year={2022}
}

@inproceedings{camgoz2017subunets,
    title={Subunets: End-to-end hand shape and continuous sign language recognition},
    author={Camg{\"o}z, Necati Cihan and Hadfield, Simon and Koller, Oscar and Bowden, Richard},
    booktitle={2017 IEEE International Conference on Computer Vision (ICCV)},
    pages={3075--3084},
    year={2017},
    organization={IEEE}
}

@article{cui2019deep,
    title={A deep neural framework for continuous sign language recognition by iterative training},
    author={Cui, Runpeng and Liu, Hu and Zhang, Changshui},
    journal={IEEE Transactions on Multimedia},
    volume={21},
    number={7},
    pages={1880--1891},
    year={2019},
    publisher={IEEE}
}

@article{carreira2017quo,
    title={Quo vadis, action recognition},
    author={Carreira, Joao and Zisserman, Andrew},
    journal={A new model and the kinetics dataset. CoRR, abs/1705.07750},
    volume={2},
    number={3},
    pages={1},
    year={2017}
}

@inproceedings{pu2019iterative,
    title={Iterative alignment network for continuous sign language recognition},
    author={Pu, Junfu and Zhou, Wengang and Li, Houqiang},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={4165--4174},
    year={2019}
}

@inproceedings{yin-etal-2021-including,
    title = "Including Signed Languages in Natural Language Processing",
    author = "Yin, Kayo  and
      Moryossef, Amit  and
      Hochgesang, Julie  and
      Goldberg, Yoav  and
      Alikhani, Malihe",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.570",
    pages = "7347--7360"
}

@inproceedings{walsh2022changing,
  title={Changing the Representation: Examining Language Representation for Neural Sign Language Production},
  author={Walsh, Harry Thomas and Saunders, Ben and Bowden, Richard},
  booktitle={LREC 2022},
  year={2022}
}
